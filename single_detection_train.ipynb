{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 1050 images belonging to 21 classes.\n",
      "Found 525 images belonging to 21 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "33/33 [==============================] - 83s 2s/step - loss: 2.7013 - accuracy: 0.2152 - val_loss: 1.6624 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "33/33 [==============================] - 71s 2s/step - loss: 1.7664 - accuracy: 0.4610 - val_loss: 1.1217 - val_accuracy: 0.6743 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "33/33 [==============================] - 72s 2s/step - loss: 1.4252 - accuracy: 0.5667 - val_loss: 0.9132 - val_accuracy: 0.7429 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "33/33 [==============================] - 76s 2s/step - loss: 1.1653 - accuracy: 0.6467 - val_loss: 0.7912 - val_accuracy: 0.7676 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "33/33 [==============================] - 75s 2s/step - loss: 1.0663 - accuracy: 0.6676 - val_loss: 0.7566 - val_accuracy: 0.7905 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "33/33 [==============================] - 67s 2s/step - loss: 0.9622 - accuracy: 0.7038 - val_loss: 0.6600 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.8997 - accuracy: 0.7210 - val_loss: 0.6573 - val_accuracy: 0.8152 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.8712 - accuracy: 0.7333 - val_loss: 0.6309 - val_accuracy: 0.8114 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "33/33 [==============================] - 61s 2s/step - loss: 0.7427 - accuracy: 0.7638 - val_loss: 0.5917 - val_accuracy: 0.8362 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "33/33 [==============================] - 57s 2s/step - loss: 0.7213 - accuracy: 0.7743 - val_loss: 0.5981 - val_accuracy: 0.8210 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "33/33 [==============================] - 62s 2s/step - loss: 0.7745 - accuracy: 0.7552 - val_loss: 0.6110 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "33/33 [==============================] - 57s 2s/step - loss: 0.6689 - accuracy: 0.7905 - val_loss: 0.5850 - val_accuracy: 0.8381 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "33/33 [==============================] - 80s 2s/step - loss: 0.6667 - accuracy: 0.7876 - val_loss: 0.5688 - val_accuracy: 0.8476 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "33/33 [==============================] - 70s 2s/step - loss: 0.5973 - accuracy: 0.8276 - val_loss: 0.5581 - val_accuracy: 0.8362 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "33/33 [==============================] - 65s 2s/step - loss: 0.5933 - accuracy: 0.8019 - val_loss: 0.6016 - val_accuracy: 0.8324 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.5875 - accuracy: 0.8095 - val_loss: 0.5516 - val_accuracy: 0.8381 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "33/33 [==============================] - 68s 2s/step - loss: 0.5286 - accuracy: 0.8305 - val_loss: 0.5600 - val_accuracy: 0.8495 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "33/33 [==============================] - 78s 2s/step - loss: 0.5121 - accuracy: 0.8400 - val_loss: 0.5254 - val_accuracy: 0.8590 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "33/33 [==============================] - 56s 2s/step - loss: 0.4982 - accuracy: 0.8467 - val_loss: 0.5360 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "33/33 [==============================] - 57s 2s/step - loss: 0.5276 - accuracy: 0.8390 - val_loss: 0.5183 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 83s 2s/step - loss: 1.7203 - accuracy: 0.5162 - val_loss: 0.5305 - val_accuracy: 0.8590 - lr: 1.0000e-05\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 68s 2s/step - loss: 1.4763 - accuracy: 0.5762 - val_loss: 0.5350 - val_accuracy: 0.8533 - lr: 1.0000e-05\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 67s 2s/step - loss: 1.0870 - accuracy: 0.6714 - val_loss: 0.5427 - val_accuracy: 0.8495 - lr: 1.0000e-05\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.7114\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "33/33 [==============================] - 68s 2s/step - loss: 0.9485 - accuracy: 0.7114 - val_loss: 0.5453 - val_accuracy: 0.8495 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 68s 2s/step - loss: 0.9498 - accuracy: 0.7114 - val_loss: 0.5435 - val_accuracy: 0.8514 - lr: 5.0000e-06\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - ETA: 0s - loss: 0.9006 - accuracy: 0.7419Restoring model weights from the end of the best epoch: 1.\n",
      "33/33 [==============================] - 68s 2s/step - loss: 0.9006 - accuracy: 0.7419 - val_loss: 0.5463 - val_accuracy: 0.8533 - lr: 5.0000e-06\n",
      "Epoch 6: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model Training Complete & Saved as 'ewaste_mobilenetv2.h5'! ðŸš€\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "\n",
    "# âœ… Define Dataset Paths\n",
    "BASE_DIR = r'C:\\Users\\lenovo\\OneDrive\\Desktop\\E-WASTE-ANALYSIS-AND-PREDICTING-RECYCLING-METHOD\\dataset\\DATASET\\modified-dataset'\n",
    "TRAIN_PATH = os.path.join(BASE_DIR, \"train\")\n",
    "VALID_PATH = os.path.join(BASE_DIR, \"valid\")\n",
    "TEST_PATH = os.path.join(BASE_DIR, \"test\")  # For testing after training\n",
    "\n",
    "# âœ… Image Properties\n",
    "IMG_SIZE = (224, 224)  # MobileNetV2 recommended size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# âœ… Stronger Data Augmentation to Improve Accuracy\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.6, 1.4],  \n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# âœ… Load Dataset\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    TRAIN_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "val_data = valid_datagen.flow_from_directory(\n",
    "    VALID_PATH, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# âœ… Load Pretrained MobileNetV2 Model\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Initially freeze the base model\n",
    "\n",
    "# âœ… Custom Classification Head\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.4)(x)  # Increased dropout for better generalization\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(len(train_data.class_indices), activation=\"softmax\")(x)  # Output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "\n",
    "# âœ… Compile Model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# âœ… Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, verbose=1)\n",
    "early_stop = EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# âœ… Train Model\n",
    "EPOCHS = 20\n",
    "history = model.fit(train_data, validation_data=val_data, epochs=EPOCHS, callbacks=[reduce_lr, early_stop])\n",
    "\n",
    "# âœ… Fine-Tune Top Layers (for Higher Accuracy)\n",
    "base_model.trainable = True  # Unfreeze base model\n",
    "for layer in base_model.layers[:100]:  # Keep first 100 layers frozen\n",
    "    layer.trainable = False\n",
    "\n",
    "# âœ… Recompile with Lower LR\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# âœ… Train Again with Fine-Tuning\n",
    "fine_tune_epochs = 10\n",
    "history_finetune = model.fit(train_data, validation_data=val_data, epochs=fine_tune_epochs, callbacks=[reduce_lr, early_stop])\n",
    "\n",
    "# âœ… Save Model\n",
    "model.save(\"ewaste_mobilenetv2.h5\")\n",
    "\n",
    "print(\"âœ… Model Training Complete & Saved as 'ewaste_mobilenetv2.h5'! ðŸš€\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
